%!TEX root=kdd15_workshop_main.tex
\section{Evaluation}

We ran our distributed experiments on the Edison machine at NERSC, featuring 5576 compute nodes with two 12-core Intel ``Ivy Bridge'' processors per node, and a Cray Aries interconnect. For scalability experiments we generated undirected Kronecker graphs of varying scale in parallel using the Graph500 Reference implementation~\cite{graph500}. 

We also measured the overall quality of partitions by the \textit{fraction of cut edges} $\lambda$.
\begin{align}\lambda = \frac{\text{Number of edges cut by partition}}{\text{Total number of edges}}\end{align}
The fraction of edges cut demonstrates the quality of the edge minimization aspect of partitioning the graph.

As a baseline, we can compare this to the expected quality of a random $k-$partition:
\begin{align}\lambda_r = \frac{k^2 - k}{k^2} = \frac{k-1}{k} \end{align}

Any partitioner that produces partitions with $\lambda < \lambda_r$ has improved the parallel locality of the partitions. 
We present $\lambda_{r,k}$ along with our one-pass, real network results in Table \ref{table:big}.

\subsection{Test Graphs}
We tested \ourmethod on both real and synthetic networks.
Real networks demonstrate \ourmethod's potential for use on real domain problems.
We also utilized synthetic graphs, because they allow better experimental control over size and structure.
\subsubsection{Real-world Graphs}
The SNAP dataset is a collection of real-world networks collected by Leskovec and collaborators~\cite{Leskovec-data, snapnets}. 
Many networks in the collection are power-law and scale-free representatives of social networks (such as collaboration networks, citation networks, email networks, and web graphs). We consider these to be ideal targets for streaming partitioning, because these domains are producing the vast majority of the `big-data' that is difficult to partition using traditional methods.

% We also speculate (but have no proof) that the `random' structure of scale-free networks better suits the random quality of streaming graph partitioning, whereas a spatially-oriented graph would be poorly suited (for instance, in a grid, a streaming partitioner would create many local pockets for one particular partition, whereas a spatial partitioner would recognize that the graph could be geometrically bisected).

\subsubsection{Synthetic Graphs}
To generate the test graphs we used the Graph500 Kronecker-Graph generator.
Kronecker graphs are commonly used in HPC graph benchmarks and testing and can be scaled arbitrarily large for testing purposes. 



\subsection{Quality}
In Table~\ref{table:big} we show some properties of our real test-graphs, as well as the performance of our streaming partitioner on them, for $k=2$ and $k=8$.
% As a note, the ratio of change in $\lambda$ from $k=2$ to $k=8$ was for the vast majority of cases within 1.5 and 2.2. 
% This suggests good scalability.


\begin{figure}
\caption{Basic properties of graphs in SNAP data set~\cite{Leskovec-data}, and $\lambda$ for one pass. $\lambda_{r,2}=0.5,\lambda_{r,8}=0.87$}
\rowcolors{2}{blue!05}{blue!15}
\centering
\small
{ \begin{tabular}{ *5r }    \toprule
\label{table:big}
\emph{Data Set} & $N$ & $nnz$  & $\lambda_{k=2}$ & $\lambda_{k=8}$ \\\midrule
soc-LiveJournal & 4,847,571 & 68,993,773  &0.234& 0.463\\
as-Skitter & 1,696,415 & 22,190,596  & 0.166&0.324\\
cit-Patents & 3,774,768 & 16,518,948  & 0.402&0.726\\
roadNet-CA & 1,971,281 & 5,533,214  & 0.186&0.360\\
web-Google & 916,428 & 5,105,039  &0.189&0.336\\
wiki-Talk & 2,394,385 & 5,021,410 &0.411&0.752\\
amazon0302 & 262,111 & 1,234,877 & 0.202&0.370\\
soc-Slashdot0902 & 82,168 & 948,464  &0.236&0.382\\
ca-AstroPh & 18,772 & 396,160 & 0.232&0.413\\
cit-HepPh & 34,546 & 421,578 & 0.343&0.646\\
email-EuAll & 265,214 & 420,045 & 0.280&0.538\\
Oregon-1 & 11,492 & 46,818  & 0.224&0.406\\
p2p-Gnutella04 & 10,879 & 39,994  & 0.415&0.747\\


 \hline
\end{tabular}\par
}
\end{figure}


%\begin{figure}
%\caption{Basic properties of graphs in SNAP data set~\cite{Leskovec-data}, and $\lambda$ for one pass. $\lambda_{r,2}=0.5,\lambda_{r,8}=0.87$}
%\rowcolors{2}{blue!05}{blue!15}
%\centering
%{ \begin{tabular}{ *5r }    \toprule
%\label{table:big}
%\emph{Data Set} & $N$ & $nnz$  & $\lambda, k=2$ & $\lambda, k=8$ \\\midrule
%amazon0302 & 262111 & 1234877 & 0.202&0.370\\
%as-Skitter & 1696415 & 22190596  & 0.166&0.324\\
%ca-AstroPh & 18772 & 396160 & 0.232&0.413\\
%cit-HepPh & 34546 & 421578 & 0.343&0.646\\
%cit-Patents & 3774768 & 16518948  & 0.402&0.726\\
%email-EuAll & 265214 & 420045 & 0.280&0.538\\
%Oregon-1 & 11492 & 46818  & 0.224&0.406\\
%p2p-Gnutella04 & 10879 & 39994  & 0.415&0.747\\
%roadNet-CA & 1971281 & 5533214  & 0.186&0.360\\
%soc-LiveJournal & 4847571 & 68993773  &0.234& 0.463\\
%soc-Slashdot0902 & 82168 & 948464  &0.236&0.382\\
%web-Google & 916428 & 5105039  &0.189&0.336\\
%wiki-Talk & 2394385 & 5021410 &0.411&0.752\\
% \hline
%\end{tabular}\par
%}
%\end{figure}


% We also note Figure~\ref{fig:4}, which illustrates the result of the streaming algorithm on a more spacial network (roadNet-CA). The `local' nonzeros are those points in the 8 diagonal blocks, while the `remote' edges are those outside. While a good partitioner would concentrate the vast majority of elements along the diagonal (which is possible because the graph has very high diameter), the streaming partitioner fails to recognize this quality, and each partition has vertices distributed somewhat randomly through the network. Nonetheless, the partition is decent (only 18 percent of edges are cut).

% \begin{figure}[h!]
% \centering
% \includegraphics[width=0.8\columnwidth] {figures/roadNet-CA8.png}
% \caption[Caption for]{Spy plot of roadNet-CA 8-partition ($\lambda=0.177$). This illustrates how a streaming algorithm cannot take into account the spatial/planar properties of a graph.}
% \label{fig:4}
% \end{figure}


% In Figure~\ref{fig:kronspeed} however, we increase the $p$-value on a single ER graph. We see that the partition quality significantly decreases. 
% This is to be expected of all partitioners in general. In fact, for E-R graphs, the critical $p$-value for which the optimal edge cut is equal to the expected average random partition is relatively simple to identify~\cite{journals/cj/GanleyH94}

\paragraph{Restreaming \& Additional Passes}
A key facet of \ourmethod is performing additional passes of partitioning on a pre-partitioned graph. 
The partitioner is fast enough that it is faster to do $n$ streaming passes than use a slower mainstream graph partitioner.
To explore this idea, we perform a number of passes on the SNAP data set, and observe the effects of various graphs (see Figure~\ref{fig:k2_lambda, fig:k16_lambda}). 

The algorithm is simple: once we have computed the first partition, we retain the original partition mapping. 
Then, as we make another pass, we compute the new objective function using the partition mapping that has already been filled in. 
Vertices may be switched to new partitions. 
This mitigates poor partitioning decisions that sometimes occur at the beginning of the algorithm, when there was not as much information.

Figures~\ref{fig:k2_lambda} and \ref{fig:k16_lambda} show the improvement of $\lambda$ as we continue to make passes over selected networks. 
The second pass usually exhibits the best improvement, while subsequent passes offer diminishing returns.
Making a low-cut 16-partitioning is considerably harder than the 2-partition case, explaining the difference in quality in Figure~\ref{fig:k16_lambda}.


% We hope to contrast this performance to that of METIS in the future. (We have implemented a METIS partitioner for comparison but it currently encounters a segmentation faults with some frequency).



\begin{figure}[t!]
\centering
\includegraphics[width=0.9\columnwidth] {figures/real_k2_lambda.pdf}
\caption[Caption for]{Improvement in the edges cut ($\lambda$) over 5 passes for bi-partitions of each graph. Because there are only two partitions, the algorithm is able to quickly fix mistakes it made in the initial partitioning. Many of the errors made in the first pass are fixed in the second iteration, with diminishing improvement thereafter.}
\label{fig:k2_lambda}
\end{figure}

\begin{figure}[t!]
\centering
\includegraphics[width=0.9\columnwidth] {figures/real_k16_lambda.pdf}
\caption[Caption for]{Improvement in edges cut ($\lambda$) over 5 passes for $k=16$-partitions of each graph. Dividing the graph into 16 partitions makes the minimum edge cut problem much more challenging. Similar to the bi-partition results, we experience the best gain in the second pass and less in subsequent passes.}
\label{fig:k16_lambda}
\end{figure}


\subsection{Scalability}
In order to test the scalability of \ourmethod we used a series of Kronecker graphs running on a state-of-the-art system.
In Figure~\ref{fig:kronqual} we illustrate the streaming graph partitioner on Kronecker graphs with a widely varying number of nodes.
We show the Kronecker graphs performance in Figure!\ref{fig:kronspeed}. 
\ourmethod is able to achieve a good balance between quality at incredible speeds.


\begin{figure}[h!]
\centering
  \includegraphics[width=0.8\columnwidth]{figures/kronecker_quality_tests.pdf}
  \caption{Partition quality of various Kronecker graphs.}
  \label{fig:kronqual}
\end{figure}

\begin{figure}[h!]
\centering
  \includegraphics[width=0.8\columnwidth]{figures/kronecker_speed_tests.pdf}
  \caption{Partition speed of various Kronecker graphs.}
  \label{fig:kronspeed}
\end{figure}


\subsection{Analysis}
% Other data from real-world was harder to analyze -- there are not enough wide differences between data sets' results to draw strong conclusions.
Despite the complexity of many of the real graphs, \ourmethod creates well-balanced partitions.
While Power-Law graphs are overwhelmingly considered to be difficult to partition~\cite{Abou-Rjeili:2006:MAP:1898953.1899055}, we have demonstrated that a very simple, fast, algorithm is capable of significantly reducing communication in their parallel computation. 
We also demonstrate in Figures~\ref{fig:k2_lambda, fig:k16_lambda} that additional passes can further reduce edges cut (by up to a factor of 3). 

% Isolated comparisons we have made to the state-of-the-art partitioner METIS show that these results are competitive (usually within a factor of 2).
In Figure~\ref{fig:metis}, \ourmethod performs comparably with parMETIS.  
Streaming partitioning is a valid alternative to conventional offline approaches and can be integrated in distributed-memory, on-the-fly algorithms for big-data.

One set of outlying (poorly-performing) data points are the Gnutella networks.
While Gnutella networks exhibit power-law-like topologies, elements of their algorithm truncate nodes from ever becoming extremely large. 
This heavy-clipping sets the Gnutella networks apart from many of the other social network topologies in our experiments.
The data set also has extremely low clustering coefficients and a very small number of closed triangles \cite{Ripeanu:2002:MGN:613352.613670}. 
Low clustering coefficients decrease the chance that neighbors of the current node-under-consideration share a partition. 
With more neighbors distributed across the partitions, many partitions will have roughly the same score, making optimal partition choices much harder.

A danger of naively running multiple passes is that one partition often becomes populated by very high-degree vertices. 
We attribute this to the ``dense core'' surrounded by a less-dense periphery that many scale-free graphs possess.
This can be observed qualitatively when scale-free graphs are embedded in a spectral space~\cite{Lang04findinggood}.

This dense partition tends to strongly emerge as we continue to make further passes of the streaming algorithm.
In order to overcome this we used the tempered parameter technique described in our methodology section. 

